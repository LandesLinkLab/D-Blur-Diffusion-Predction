{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an example on experiment data analysis. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [1. Imports & Model Setup](#Imports-&-Model-Setup)  \n",
    "- [2. Single‑File Check](#Single‑File-Check)  \n",
    "- [3. Multi‑File Aggregation](#Multi‑File-Aggregation)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports-&-Model-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed package \n",
    "import numpy as np \n",
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "from utils.data_loader import expdata_preprocess, data_loader_exp, load_file\n",
    "from utils.post_analysis import re_group_exp, find_particle_locations\n",
    "from model import unet_locD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the path\n",
    "\n",
    "\n",
    "dir_exp = 'Z:/Dongyu Fan/2. Data/4D data/02192025/crop/'  # Set this as where your data are. \n",
    "\n",
    "\n",
    "# Set up the model: \n",
    "dir_model = 'C:/Users/dongyuf2/OneDrive - University of Illinois - Urbana/shareddrive/2. Data/ImageProcessing/Training/2025-02-14/02-14_00-16/model_checkpoint_3.pth'  # Set this at where your model is \n",
    "D_range = [0.01, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model \n",
    "# Initialize the model \n",
    "model = unet_locD(n_channels=3, n_classes=1,bilinear=False)\n",
    "# Load the saved state_dict\n",
    "model.load_state_dict(torch.load(dir_model,map_location=torch.device('cpu') ))\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# 3.  Perform evaluation\n",
    "# Set up the device: \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some parameter for cropping\n",
    "patchsize = 64 # The spatial size for every patch. Match that of the model input.\n",
    "overlap = 0.2  # 20% of overlap between patches.\n",
    "stacksize = 3  # The number of frames to take in every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single‑File-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files\n",
    "\n",
    "# load the data and break into small pieces and save \n",
    "\n",
    "imgfile = 'gbeads_100nm_30gly_2D_00_crop.tif'\n",
    "\n",
    "# create a subfolder for saving first: \n",
    "crop_save = dir_exp +  imgfile[:-4] + '/'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(crop_save, exist_ok=True)  # exist_ok=True to avoid error if the directory already exists\n",
    "\n",
    "expdata_preprocess(dir_exp + imgfile, crop_save, patchsize, overlap, stacksize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the loaded data:\n",
    "\n",
    "dataset = data_loader_exp(crop_save)\n",
    "#loader_args = dict(batch_size=1, num_workers=os.cpu_count(), pin_memory=True) # Multi processing introduces errors\n",
    "exp_data = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "for batch in exp_data:\n",
    "    a = (batch['image'])\n",
    "    ind = batch['index']\n",
    "    a = a.squeeze(0)   # Reduce the dimension for batch. \n",
    "    #print(a.max())\n",
    "    \n",
    "    plt.imshow(a[0,:,:])\n",
    "    plt.show()\n",
    "    break \n",
    "\n",
    "# Plot an example frame from a crop \n",
    "#plt.imshow(a[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Input into the model \n",
    "# send the model to device\n",
    "model = model.to(device)\n",
    "# set the path for result saving \n",
    "result_save = crop_save + 'result/'\n",
    "# create the path if needed \n",
    "os.makedirs(result_save, exist_ok=True)  # exist_ok=True to avoid error if the directory already exists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the evaluation \n",
    "for batch in exp_data:\n",
    "    images = batch['image']\n",
    "    #images = images.squeeze(0)   # Reduce the dimension for batch. \n",
    "    #print(images.max())\n",
    "    images = images.to(device)\n",
    "    \n",
    "    index = batch['index']\n",
    "    # Forward pass\n",
    "    pred = model(images)  # Ensure you unpack the outputs\n",
    "    #pred = torch.sigmoid(pred).squeeze().detach().numpy()\n",
    "    pred = torch.sigmoid(pred).to(dtype=torch.float32).squeeze().permute(1,2,0).detach().cpu().numpy()\n",
    "    np.savez(result_save + 'result_' + str(index.detach().numpy()[0]) + '.npz', result = pred)\n",
    "    #plt.imshow(np.sum(pred,axis = 2))\n",
    "    #plt.show()\n",
    "\n",
    "    #print(find_particle_locations(pred))\n",
    "    \n",
    "    #break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroup the output small patches: \n",
    "reconstructed_result = re_group_exp(result_save, 64,64,1000, patchsize,overlap,stacksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look of the output \n",
    "plt.imshow(np.sum(reconstructed_result[:,:,:,100],axis = 2),cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_img = load_file(dir_exp + imgfile)\n",
    "# Take a look of the original image for comparison\n",
    "plt.imshow(original_img[300,:,:] , cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do fittings on the recovered results. \n",
    "# Parameters\n",
    "neighborhood_size = 1  # Adjust for PSF size\n",
    "threshold = 0.25  # Adjust based on noise level! This is the main parameter to adjust here.\n",
    "location_all = []\n",
    "for stack in range(reconstructed_result.shape[3]):\n",
    "    particle_locations = find_particle_locations(reconstructed_result[:,:,:,stack], neighborhood_size, threshold)\n",
    "    location_all.append(particle_locations)\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the recovered results overlay on the original result \n",
    "\n",
    "stack = 0\n",
    "\n",
    "\n",
    "for frame in range(stacksize):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(original_img[stack * 3 + frame,:,:] , cmap = 'gray')\n",
    "    #ax.imshow(original_img[200 * 3 + frame,:,:] , cmap = 'gray')\n",
    "    for pair in location_all[stack]:\n",
    "        x,y,d = pair\n",
    "        plt.scatter(x,y,marker = 'o', edgecolors= 'red', s = 100, facecolor = 'None' )\n",
    "        D = ((d - 2) / 9 ) * (D_range[1] - D_range[0]) + D_range[0] \n",
    "        plt.text( x  -2, y -2, f'{D:.2f}', color = 'red')\n",
    "\n",
    "    # Remove axis labels and ticks\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Add a scale bar\n",
    "\n",
    "    scalebar = ScaleBar(0.1, 'um', location = 'lower right', box_alpha = 0.5)\n",
    "    ax.add_artist(scalebar)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plotted results s a movie \n",
    "\n",
    "plots_save = crop_save + 'plots/retrained_model/'\n",
    "os.makedirs(plots_save, exist_ok=True)\n",
    "\n",
    "for stack in range(np.shape(reconstructed_result)[3]):\n",
    "#for stack in range(100):\n",
    "    for frame in range(stacksize):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(original_img[stack * 3 + frame,:,:] , cmap = 'gray')\n",
    "        for pair in location_all[stack]:\n",
    "            x,y,d = pair\n",
    "            D = ((d - 2) / 9 ) * (D_range[1] - D_range[0]) + D_range[0] \n",
    "            #if D > 1.75:\n",
    "            #    continue \n",
    "            plt.scatter(x,y,marker = 'o', edgecolors= 'red', s = 100, facecolor = 'None' )\n",
    "\n",
    "            plt.text( x- 2, y - 2, f'{D:.2f}', color = 'red')\n",
    "\n",
    "        # Remove axis labels and ticks\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Add a scale bar\n",
    "\n",
    "        scalebar = ScaleBar(0.1, 'um', location = 'lower right', box_alpha = 0.5)\n",
    "        ax.add_artist(scalebar)\n",
    "\n",
    "        plt.savefig(plots_save + f'Plots_{stack*3 + frame}.png')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output movie to see if identifications are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the histogram data for plotting in the matlab \n",
    "import scipy\n",
    "D_array = np.array(D_all)\n",
    "os.makedirs(crop_save + 'output/', exist_ok = True)\n",
    "scipy.io.savemat(crop_save + 'output/D.mat',{'D_array' : D_array})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. List a map \n",
    "# Let's do this whole thing for all the data:\n",
    "\n",
    "# Start the evaluation: \n",
    "# Initiate the arrays \n",
    "canvas = np.zeros((64, 64), dtype=float)\n",
    "count = np.zeros((64, 64), dtype=int)\n",
    "\n",
    "\n",
    "for frame in location_all:\n",
    "    for particle in frame:      \n",
    "        x =  particle[0].astype(int)\n",
    "        y = particle[1].astype(int)\n",
    "        values = ((particle[2] - 2) / 9.0) * (D_range[1] - D_range[0]) + D_range[0]\n",
    "        # Accumulate sums and counts using np.add.at\n",
    "        if values < 1.7:\n",
    "            np.add.at(canvas, (y, x), values)  \n",
    "            np.add.at(count, (y, x), 1)\n",
    "\n",
    "\n",
    "# Take care of the post process:\n",
    "\n",
    "canvas_all = np.zeros_like(canvas)\n",
    "np.divide(canvas, count, out=canvas_all, where=(count != 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the diffusion map:\n",
    "\n",
    "plt.imshow(canvas_all,cmap = 'jet')\n",
    "plt.colorbar()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi‑File-Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads files: \n",
    "\n",
    "file_stem = 'roi_agrose08_fov2'   # The name of the file starts with \n",
    "files = glob.glob(os.path.join(dir_exp,file_stem+'*.tif'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate some files\n",
    "location_all_comb = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the files \n",
    "for file in files:\n",
    "    \n",
    "\n",
    "    # create a subfolder for saving first: \n",
    "    crop_save = file[:-4] + '/'\n",
    "\n",
    "    # Create directories\n",
    "    os.makedirs(crop_save, exist_ok=True)  # exist_ok=True to avoid error if the directory already exists\n",
    "\n",
    "    expdata_preprocess(file, crop_save, patchsize, overlap, stacksize)\n",
    "\n",
    "\n",
    "    # Setup the location for saving results: \n",
    "    result_save = crop_save + 'result/'\n",
    "    # create the path if needed \n",
    "    os.makedirs(result_save, exist_ok=True)  # exist_ok=True to avoid error if the directory already exists\n",
    "\n",
    "\n",
    "    # Load data:\n",
    "\n",
    "    \n",
    "    dataset = data_loader_exp(crop_save)\n",
    "    #loader_args = dict(batch_size=1, num_workers=os.cpu_count(), pin_memory=True) # Multi processing introduces errors\n",
    "    exp_data = DataLoader(dataset,batch_size=1)\n",
    "    # Then read and pred \n",
    "    # Start the evaluation \n",
    "    \n",
    "    for batch in exp_data:\n",
    "        images = batch['image']\n",
    "        images = images.to(device)\n",
    "        \n",
    "        index = batch['index']\n",
    "        # Forward pass\n",
    "        pred = model(images)  # Ensure you unpack the outputs\n",
    "        pred = torch.sigmoid(pred).to(dtype=torch.float32).squeeze().permute(1,2,0).detach().cpu().numpy()\n",
    "        np.savez(result_save + 'result_' + str(index.detach().numpy()[0]) + '.npz', result = pred)\n",
    "    \n",
    "    # Then get the locations:\n",
    "    # Regroup the output small patches: \n",
    "    reconstructed_result = re_group_exp(result_save, 64,64,2000, patchsize,overlap,stacksize)\n",
    "\n",
    "    # Do fittings on the recovered results. \n",
    "    # Parameters\n",
    "    neighborhood_size = 1  # Adjust for PSF size\n",
    "    threshold = 0.4  # Adjust based on noise level\n",
    "    for stack in range(reconstructed_result.shape[3]):\n",
    "        particle_locations = find_particle_locations(reconstructed_result[:,:,:,stack], neighborhood_size, threshold)\n",
    "        location_all_comb.extend(particle_locations)\n",
    "        #break\n",
    "    \n",
    "    print(\"Finished Process \" + file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do this whole thing for all data in the same FOV\n",
    "\n",
    "# Start the evaluation: \n",
    "# Initiate the arrays \n",
    "canvas = np.zeros((64, 64), dtype=float)\n",
    "count = np.zeros((64, 64), dtype=int)\n",
    "\n",
    "D_all = []\n",
    "for particle in location_all_comb:\n",
    "     \n",
    "    x =  particle[0].astype(int)\n",
    "    y = particle[1].astype(int)\n",
    "    values = ((particle[2] - 2) / 9.0) * (D_range[1] - D_range[0]) + D_range[0]\n",
    "    # Accumulate sums and counts using np.add.at\n",
    "    #if values != error_value:\n",
    "    if values < 2.1:\n",
    "        np.add.at(canvas, (y, x), values)  \n",
    "        np.add.at(count, (y, x), 1)\n",
    "        D_all.append(values)\n",
    "\n",
    "\n",
    "# Take care of the post process:\n",
    "\n",
    "canvas_all = np.zeros_like(canvas)\n",
    "np.divide(canvas, count, out=canvas_all, where=(count > 4) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save if needed: \n",
    "#np.savez(dir_exp + 'fov2.npz', D_all=D_all, location_all = location_all_comb)\n",
    "\n",
    "# Import if needed:\n",
    "#data = np.load(dir_exp + 'fov3.npz' )\n",
    "#D_all = data['D_all']\n",
    "#location_all_comb = data['location_all']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save matlab if needed.\n",
    "import scipy\n",
    "#scipy.io.savemat(dir_exp + 'fov3.mat', {'D_all': D_all, 'location_all':location_all_comb} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the Diffusion map \n",
    "plt.imshow(canvas_all,cmap = 'jet')\n",
    "plt.colorbar()\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
