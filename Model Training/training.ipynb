{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training UNet for Diffusion Prediction\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [1. Imports & Model Setup](#Imports-&-Model-Setup)  \n",
    "- [2. Data Loading & Check](#Data-Loading-&-Check)  \n",
    "- [3. Training Loop](#Training-Loop)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports-&-Model-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Internal import \n",
    "from model import unet_locD\n",
    "from utils.data_loader import data_loader\n",
    "from utils.loss_calculator import calculate_loss\n",
    "from utils.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the folders\n",
    "\n",
    "dir_img = 'path/imgpadding/'  # Set where the image files are, by default should be in the folder imgpadding\n",
    "dir_label ='path/labelpading' # Set where the image files are, by default should be in the folder labelpading\n",
    "dir_pair = 'path/pairpading/' # Set where the image files are, by default should be in the folder pairpading\n",
    "\n",
    "\n",
    "label_suffix = '_loc'\n",
    "pair_suffix = '_pair'\n",
    "\n",
    "\n",
    "# Set up the parameter:\n",
    "D_range = [0.01, 2]  # The Diffusion efficient range this data is simulated with. For normalization purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Loading-&-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model: \n",
    "model = unet_locD(n_channels=3, n_classes=1, bilinear=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "data = data_loader(dir_img, dir_label,dir_pair, label_suffix, pair_suffix)\n",
    "dataset = DataLoader(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one slice of data\n",
    "i = 0 \n",
    "example_frame = 1 # Set which one to take\n",
    "for batch in dataset:\n",
    "    images, labels = batch['image'], batch['label']\n",
    "    i += 1\n",
    "    if i == example_frame:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the label is: {labels.shape}\")\n",
    "print(f\"The shape of the image is: {images.shape}\")\n",
    "\n",
    "# The shape of the label should be 14 * 64 * 64 \n",
    "# The shape of the image should be 3 (channels)  * 64 * 64\n",
    "# If the shape is not right, adjust transpose in the data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take a look of the data\n",
    "\n",
    "plt.imshow(np.sum(images.detach().numpy()[0],0), alpha = 0.5)\n",
    "plt.show()\n",
    "label2 = np.sum(labels.detach().numpy()[0],0)\n",
    "label2 = label2.transpose(1,0)\n",
    "plt.imshow(label2, alpha = 0.5)\n",
    "\n",
    "\n",
    "# If the label and image doesn't match each other, check the transpose in data loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a folder for storing the training model. \n",
    "from datetime import datetime\n",
    " # Define the base path\n",
    "base_path = 'path/training'  # Set up where you'd like the save the trained model.\n",
    "\n",
    "\n",
    "# Get current date and time\n",
    "now = datetime.now()\n",
    "date_str = now.strftime('%Y-%m-%d')  # Format for date (e.g., '2024-08-26')\n",
    "time_str = now.strftime('%m-%d_%H-%M')  # Format for time (e.g., '08-26_15-30')\n",
    "\n",
    "# Create directory paths\n",
    "date_folder = os.path.join(base_path, date_str)\n",
    "time_folder = os.path.join(date_folder, time_str)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(time_folder, exist_ok=True)  # exist_ok=True to avoid error if the directory already exists\n",
    "\n",
    "dir_checkpoint = time_folder\n",
    "wandb_dir = time_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training the model \n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')\n",
    "\n",
    "# Change here to adapt to your data\n",
    "# n_classes is the number of probabilities you want to get per pixel\n",
    "model = unet_locD(n_channels=3, n_classes=1, bilinear=False)   # Change channel accordingly \n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "\n",
    "logging.info(f'Network:\\n'\n",
    "                 f'\\t{model.n_channels} input channels\\n'\n",
    "                 f'\\t{model.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "model.to(device=device)\n",
    "try:\n",
    "   predction, truth, images, loss = train(\n",
    "    #masks_pred_bi, masks_pred = test_train(\n",
    "        model=model,\n",
    "        dir_img = dir_img, \n",
    "        dir_label = dir_label,\n",
    "        dir_pair = dir_pair, \n",
    "        label_suffix = label_suffix, \n",
    "        pair_suffix = pair_suffix,\n",
    "        wandb_dir = wandb_dir,\n",
    "        dir_checkpoint = dir_checkpoint,\n",
    "        epochs=100,\n",
    "        batch_size=8,\n",
    "        learning_rate=1e-5,   # It was 1e-5\n",
    "        device=device,\n",
    "        val_percent=0.1,\n",
    "        amp=False,\n",
    "        wandb_log = True,\n",
    "        save_checkpoint= True\n",
    "\n",
    "    )\n",
    "\n",
    "except torch.cuda.OutOfMemoryError:\n",
    "    logging.error('Detected OutOfMemoryError! '\n",
    "                    'Enabling checkpointing to reduce memory usage, but this slows down training. '\n",
    "                    'Consider enabling AMP (--amp) for fast and memory efficient training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to weight and bias to check the training results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sim_psf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
